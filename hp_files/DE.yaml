{
  "blocks": 15,
  "hidden": 256,
  "layers": 2,
  "use_batch_norm": False,
  "learning_rate": 0.001,
  "batch_size": 1024,
  "epochs": 200,
  "weight_decay": 0.000001, 
  "optimizer": "AdamW",
  "lr_scheduler": True
}